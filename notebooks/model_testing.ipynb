{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bt6iK3Y0i4_F"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, Sequential\n",
        "from tensorflow.keras.layers import Dense, GlobalAvgPool2D\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from tensorflow.keras.applications import ResNet152V2, InceptionV3\n",
        "from google.cloud import storage\n",
        "from google.colab import drive\n",
        "import wandb\n",
        "from wandb.integration.keras import WandbCallback\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing\n",
        "\n",
        "## First step\n",
        "\n",
        "Download the tensorized tfrecord from GCP"
      ],
      "metadata": {
        "id": "YKInp_t3ibyd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_tesorized_data_from_bucket(secrets_path, bucket_name, local_dir):\n",
        "    client = storage.Client.from_service_account_json(secrets_path)\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blobs = bucket.list_blobs()\n",
        "\n",
        "    os.makedirs(local_dir, exist_ok=True)\n",
        "\n",
        "    for blob in blobs:\n",
        "        local_path = os.path.join(local_dir, blob.name)\n",
        "        local_dir_path = os.path.dirname(local_path)\n",
        "        os.makedirs(local_dir_path, exist_ok=True)\n",
        "\n",
        "        blob.download_to_filename(local_path)\n",
        "        print(f\"Downloaded {blob.name} to {local_path}\")"
      ],
      "metadata": {
        "id": "PtTUbQn7tM5K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set up secret variables and GCP credentials"
      ],
      "metadata": {
        "id": "Tg4cHoLSipFD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SECRETS_PATH = '/content/data-service-account-model.json'\n",
        "BUCKET_NAME = 'tensor-bucket-20k'\n",
        "LOCAL_PATH = '/content/tensor'\n",
        "download_tesorized_data_from_bucket(SECRETS_PATH, BUCKET_NAME, LOCAL_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OztV8FED7ja5",
        "outputId": "ecc4a7f3-ee76-4d37-81f7-c2ee157e83bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloaded data.tfrecord to /content/tensor/data.tfrecord\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "LOCAL_TFRECORD_PATH = '/content/tensor/data.tfrecord'\n",
        "raw_dataset = tf.data.TFRecordDataset(LOCAL_TFRECORD_PATH)"
      ],
      "metadata": {
        "id": "uPloTrad-8Qz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Second Step\n",
        "\n",
        "Parse the downloaded tfrecord and prepare the data for later model testing"
      ],
      "metadata": {
        "id": "1KOAyNSriwV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_description = {\n",
        "    'image_raw': tf.io.FixedLenFeature([], tf.string),\n",
        "    'label': tf.io.FixedLenFeature([], tf.int64),\n",
        "}"
      ],
      "metadata": {
        "id": "ZQMbtZZn7p_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_tfrecord(LOCAL_TFRECORD_PATH):\n",
        "    # Parse the tensorized data using the feature description\n",
        "    parsed_example = tf.io.parse_single_example(LOCAL_TFRECORD_PATH, feature_description)\n",
        "\n",
        "    # Decode the raw bytes to get the image\n",
        "    image = tf.io.decode_raw(parsed_example['image_raw'], tf.uint8)\n",
        "    image = tf.reshape(image, [IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS])\n",
        "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0, 1]\n",
        "\n",
        "    # Get the label\n",
        "    label = parsed_example['label']\n",
        "    return image, label"
      ],
      "metadata": {
        "id": "duNUd2WCx2ST"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "LOCAL_TFRECORD_PATH = '/content/tensor/data.tfrecord'\n",
        "IMAGE_HEIGHT = 224\n",
        "IMAGE_WIDTH = 224\n",
        "NUM_CHANNELS = 3"
      ],
      "metadata": {
        "id": "u-Jc4MlZ-CLk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parsed_dataset = raw_dataset.map(parse_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "VKgeSONgBW65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Determine the number of classes (different car model, year, and make) in the data"
      ],
      "metadata": {
        "id": "FfWC76iajFpv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Determine the number of classes\n",
        "labels = []\n",
        "for _, label in parsed_dataset:\n",
        "    labels.append(label.numpy())\n",
        "unique_labels = set(labels)\n",
        "NUM_CLASSES = len(unique_labels)\n",
        "print(f\"Number of classes: {NUM_CLASSES}\")\n",
        "\n",
        "# One-hot encode labels if using categorical crossentropy\n",
        "def one_hot_encode(image, label):\n",
        "    label = tf.one_hot(label, NUM_CLASSES)\n",
        "    return image, label\n",
        "\n",
        "parsed_dataset = parsed_dataset.map(one_hot_encode, num_parallel_calls=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edg4k7pLB8vd",
        "outputId": "767d3b54-edfe-4fdf-b851-2d12e44b8911"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes: 196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Perform random train-validation split on the data"
      ],
      "metadata": {
        "id": "vA5sceTZjQ2S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Shuffle and split the dataset into training and validation sets\n",
        "dataset = parsed_dataset.shuffle(buffer_size=10000)\n",
        "dataset_size = len(labels)\n",
        "train_size = int(0.8 * dataset_size)\n",
        "val_size = dataset_size - train_size\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Batch and prefetch the datasets\n",
        "BATCH_SIZE = 32\n",
        "train_dataset = train_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "XLLLIdfzCRaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(train_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "mO7i2lcZCvrX",
        "outputId": "a567e70b-68fc-418a-884a-c1e99b73c83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensorflow.python.data.ops.prefetch_op._PrefetchDataset"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>tensorflow.python.data.ops.prefetch_op._PrefetchDataset</b><br/>def __init__(input_dataset, buffer_size, slack_period=None, name=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/prefetch_op.py</a>A `Dataset` that asynchronously prefetches its input.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 31);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Third Step\n",
        "\n",
        "Finetune the model with ResNet152V2 weights with 3 layers in the fully-connected layers and Leaky ReLu as the activation function"
      ],
      "metadata": {
        "id": "kX-k49P6jdvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Name\n",
        "name1 = \"CarNetV1\"\n",
        "\n",
        "# Pretrained Model\n",
        "base_model = ResNet152V2(include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), weights='imagenet')\n",
        "base_model.trainable = False # Freeze the Weights\n",
        "\n",
        "# Model\n",
        "CarNetV1 = Sequential([\n",
        "    base_model,\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(224, activation='leaky_relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "], name=name1)\n",
        "\n",
        "CarNetV1.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssIpgyc_SPH",
        "outputId": "c8bec3f5-d380-4b99-e37a-45ae5ad0bca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet152v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m234545216/234545216\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "EPOCHS = 100\n",
        "start_time = time.time()\n",
        "history = CarNetV1.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "execution_time = (time.time() - start_time) / 60.0\n",
        "print(f\"Training completed in {execution_time:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfMv5_0oD33S",
        "outputId": "f44b1541-66e5-408b-f581-a2453555e8e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "    500/Unknown \u001b[1m111s\u001b[0m 167ms/step - accuracy: 0.0932 - loss: 4.4468"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 2.48677, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 236ms/step - accuracy: 0.0933 - loss: 4.4455 - val_accuracy: 0.3882 - val_loss: 2.4868\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 173ms/step - accuracy: 0.4041 - loss: 2.3882\n",
            "Epoch 2: val_loss improved from 2.48677 to 1.69286, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 228ms/step - accuracy: 0.4042 - loss: 2.3880 - val_accuracy: 0.5742 - val_loss: 1.6929\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.5673 - loss: 1.6414\n",
            "Epoch 3: val_loss improved from 1.69286 to 1.22908, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 231ms/step - accuracy: 0.5673 - loss: 1.6414 - val_accuracy: 0.6858 - val_loss: 1.2291\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.6940 - loss: 1.1532\n",
            "Epoch 4: val_loss improved from 1.22908 to 0.88513, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 231ms/step - accuracy: 0.6940 - loss: 1.1533 - val_accuracy: 0.7742 - val_loss: 0.8851\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.7749 - loss: 0.8523\n",
            "Epoch 5: val_loss improved from 0.88513 to 0.65348, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 232ms/step - accuracy: 0.7749 - loss: 0.8524 - val_accuracy: 0.8300 - val_loss: 0.6535\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.8437 - loss: 0.5993\n",
            "Epoch 6: val_loss improved from 0.65348 to 0.48099, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 232ms/step - accuracy: 0.8436 - loss: 0.5994 - val_accuracy: 0.8835 - val_loss: 0.4810\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 176ms/step - accuracy: 0.8825 - loss: 0.4499\n",
            "Epoch 7: val_loss improved from 0.48099 to 0.38463, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 231ms/step - accuracy: 0.8825 - loss: 0.4500 - val_accuracy: 0.9060 - val_loss: 0.3846\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 177ms/step - accuracy: 0.9108 - loss: 0.3440\n",
            "Epoch 8: val_loss improved from 0.38463 to 0.31629, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 233ms/step - accuracy: 0.9108 - loss: 0.3441 - val_accuracy: 0.9205 - val_loss: 0.3163\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9376 - loss: 0.2551\n",
            "Epoch 9: val_loss improved from 0.31629 to 0.24987, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 233ms/step - accuracy: 0.9375 - loss: 0.2552 - val_accuracy: 0.9385 - val_loss: 0.2499\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9527 - loss: 0.1968\n",
            "Epoch 10: val_loss improved from 0.24987 to 0.17013, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 233ms/step - accuracy: 0.9527 - loss: 0.1968 - val_accuracy: 0.9617 - val_loss: 0.1701\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9627 - loss: 0.1598\n",
            "Epoch 11: val_loss improved from 0.17013 to 0.17000, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m118s\u001b[0m 233ms/step - accuracy: 0.9627 - loss: 0.1598 - val_accuracy: 0.9540 - val_loss: 0.1700\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 178ms/step - accuracy: 0.9651 - loss: 0.1366\n",
            "Epoch 12: val_loss did not improve from 0.17000\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 229ms/step - accuracy: 0.9651 - loss: 0.1367 - val_accuracy: 0.9495 - val_loss: 0.1735\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9657 - loss: 0.1360\n",
            "Epoch 13: val_loss improved from 0.17000 to 0.14026, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 235ms/step - accuracy: 0.9657 - loss: 0.1361 - val_accuracy: 0.9620 - val_loss: 0.1403\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9655 - loss: 0.1289\n",
            "Epoch 14: val_loss did not improve from 0.14026\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 229ms/step - accuracy: 0.9655 - loss: 0.1290 - val_accuracy: 0.9532 - val_loss: 0.1632\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9622 - loss: 0.1350\n",
            "Epoch 15: val_loss did not improve from 0.14026\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 230ms/step - accuracy: 0.9622 - loss: 0.1350 - val_accuracy: 0.9535 - val_loss: 0.1568\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9644 - loss: 0.1271\n",
            "Epoch 16: val_loss improved from 0.14026 to 0.13352, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 234ms/step - accuracy: 0.9644 - loss: 0.1271 - val_accuracy: 0.9638 - val_loss: 0.1335\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9656 - loss: 0.1196\n",
            "Epoch 17: val_loss improved from 0.13352 to 0.08683, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 236ms/step - accuracy: 0.9656 - loss: 0.1196 - val_accuracy: 0.9755 - val_loss: 0.0868\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step - accuracy: 0.9766 - loss: 0.0815\n",
            "Epoch 18: val_loss did not improve from 0.08683\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m117s\u001b[0m 230ms/step - accuracy: 0.9766 - loss: 0.0815 - val_accuracy: 0.9578 - val_loss: 0.1378\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 189ms/step - accuracy: 0.9707 - loss: 0.0973\n",
            "Epoch 19: val_loss did not improve from 0.08683\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 241ms/step - accuracy: 0.9707 - loss: 0.0973 - val_accuracy: 0.9572 - val_loss: 0.1398\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9702 - loss: 0.1043\n",
            "Epoch 20: val_loss did not improve from 0.08683\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9702 - loss: 0.1043 - val_accuracy: 0.9668 - val_loss: 0.1247\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9658 - loss: 0.1058\n",
            "Epoch 21: val_loss did not improve from 0.08683\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 239ms/step - accuracy: 0.9658 - loss: 0.1058 - val_accuracy: 0.9532 - val_loss: 0.1460\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9737 - loss: 0.0857\n",
            "Epoch 22: val_loss improved from 0.08683 to 0.06871, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.9737 - loss: 0.0857 - val_accuracy: 0.9758 - val_loss: 0.0687\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.9719 - loss: 0.0861\n",
            "Epoch 23: val_loss improved from 0.06871 to 0.06485, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 245ms/step - accuracy: 0.9719 - loss: 0.0861 - val_accuracy: 0.9820 - val_loss: 0.0648\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9824 - loss: 0.0588\n",
            "Epoch 24: val_loss did not improve from 0.06485\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9824 - loss: 0.0588 - val_accuracy: 0.9597 - val_loss: 0.1245\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9637 - loss: 0.1139\n",
            "Epoch 25: val_loss did not improve from 0.06485\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9637 - loss: 0.1138 - val_accuracy: 0.9635 - val_loss: 0.1195\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9737 - loss: 0.0817\n",
            "Epoch 26: val_loss did not improve from 0.06485\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9737 - loss: 0.0817 - val_accuracy: 0.9685 - val_loss: 0.0974\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9719 - loss: 0.0925\n",
            "Epoch 27: val_loss improved from 0.06485 to 0.05251, saving model to best_model.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 243ms/step - accuracy: 0.9719 - loss: 0.0925 - val_accuracy: 0.9827 - val_loss: 0.0525\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9822 - loss: 0.0604\n",
            "Epoch 28: val_loss did not improve from 0.05251\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9822 - loss: 0.0604 - val_accuracy: 0.9682 - val_loss: 0.0951\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9794 - loss: 0.0691\n",
            "Epoch 29: val_loss did not improve from 0.05251\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9794 - loss: 0.0692 - val_accuracy: 0.9770 - val_loss: 0.0764\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9789 - loss: 0.0660\n",
            "Epoch 30: val_loss did not improve from 0.05251\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9788 - loss: 0.0660 - val_accuracy: 0.9735 - val_loss: 0.0909\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9814 - loss: 0.0607\n",
            "Epoch 31: val_loss did not improve from 0.05251\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9814 - loss: 0.0608 - val_accuracy: 0.9780 - val_loss: 0.0733\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9735 - loss: 0.0837\n",
            "Epoch 32: val_loss did not improve from 0.05251\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9735 - loss: 0.0837 - val_accuracy: 0.9718 - val_loss: 0.0829\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 27.\n",
            "Training completed in 64.32 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CarNetV1\n",
        "val_loss, val_accuracy = CarNetV1.evaluate(val_dataset)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "id": "WqCYgLBzH7VK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a978be0-7735-4bff-d0e4-4bad909116e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 187ms/step - accuracy: 0.9763 - loss: 0.0586\n",
            "Validation Loss: 0.05348135158419609\n",
            "Validation Accuracy: 0.9807500243186951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetune the model with ResNet152V2 weights with 4 layers in the fully-connected layers and ReLu as the activation function"
      ],
      "metadata": {
        "id": "n-4OriyKkBi-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Name\n",
        "name2 = \"CarNetV2\"\n",
        "\n",
        "# Pretrained Model\n",
        "base_model = ResNet152V2(include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), weights='imagenet')\n",
        "base_model.trainable = False # Freeze the Weights\n",
        "\n",
        "# Model\n",
        "CarNetV2 = Sequential([\n",
        "    base_model,\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(448, activation='relu'),\n",
        "    Dense(224, activation='relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "], name=name2)\n",
        "\n",
        "CarNetV2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model2.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "id": "ATjfXKpWvkcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "EPOCHS = 100\n",
        "start_time = time.time()\n",
        "history = CarNetV2.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "execution_time = (time.time() - start_time) / 60.0\n",
        "print(f\"Training completed in {execution_time:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41wS69Hhwg1v",
        "outputId": "73a2f6f5-de9e-4453-a183-8625507c946e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "    500/Unknown \u001b[1m117s\u001b[0m 188ms/step - accuracy: 0.0596 - loss: 4.6207"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 3.05169, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 262ms/step - accuracy: 0.0597 - loss: 4.6196 - val_accuracy: 0.2362 - val_loss: 3.0517\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.2605 - loss: 2.9535\n",
            "Epoch 2: val_loss improved from 3.05169 to 2.32645, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 246ms/step - accuracy: 0.2605 - loss: 2.9532 - val_accuracy: 0.3938 - val_loss: 2.3265\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.4019 - loss: 2.2529\n",
            "Epoch 3: val_loss improved from 2.32645 to 1.77350, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.4019 - loss: 2.2528 - val_accuracy: 0.5228 - val_loss: 1.7735\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.5222 - loss: 1.7553\n",
            "Epoch 4: val_loss improved from 1.77350 to 1.40754, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 245ms/step - accuracy: 0.5222 - loss: 1.7553 - val_accuracy: 0.6003 - val_loss: 1.4075\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.6088 - loss: 1.3799\n",
            "Epoch 5: val_loss improved from 1.40754 to 1.13195, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.6088 - loss: 1.3799 - val_accuracy: 0.6865 - val_loss: 1.1319\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 188ms/step - accuracy: 0.6949 - loss: 1.0557\n",
            "Epoch 6: val_loss improved from 1.13195 to 0.84033, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 245ms/step - accuracy: 0.6949 - loss: 1.0558 - val_accuracy: 0.7663 - val_loss: 0.8403\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.7601 - loss: 0.8232\n",
            "Epoch 7: val_loss improved from 0.84033 to 0.69071, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m125s\u001b[0m 246ms/step - accuracy: 0.7601 - loss: 0.8233 - val_accuracy: 0.8067 - val_loss: 0.6907\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8147 - loss: 0.6455\n",
            "Epoch 8: val_loss improved from 0.69071 to 0.57203, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.8147 - loss: 0.6456 - val_accuracy: 0.8367 - val_loss: 0.5720\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8547 - loss: 0.5031\n",
            "Epoch 9: val_loss improved from 0.57203 to 0.42946, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.8547 - loss: 0.5032 - val_accuracy: 0.8802 - val_loss: 0.4295\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.8749 - loss: 0.4130\n",
            "Epoch 10: val_loss improved from 0.42946 to 0.39516, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 245ms/step - accuracy: 0.8749 - loss: 0.4131 - val_accuracy: 0.8835 - val_loss: 0.3952\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9065 - loss: 0.3133\n",
            "Epoch 11: val_loss improved from 0.39516 to 0.27310, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.9065 - loss: 0.3134 - val_accuracy: 0.9185 - val_loss: 0.2731\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9229 - loss: 0.2598\n",
            "Epoch 12: val_loss did not improve from 0.27310\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9229 - loss: 0.2599 - val_accuracy: 0.9110 - val_loss: 0.2967\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9267 - loss: 0.2390\n",
            "Epoch 13: val_loss improved from 0.27310 to 0.18673, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 245ms/step - accuracy: 0.9267 - loss: 0.2391 - val_accuracy: 0.9440 - val_loss: 0.1867\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9300 - loss: 0.2173\n",
            "Epoch 14: val_loss did not improve from 0.18673\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9300 - loss: 0.2174 - val_accuracy: 0.9285 - val_loss: 0.2341\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9322 - loss: 0.2192\n",
            "Epoch 15: val_loss improved from 0.18673 to 0.18461, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.9322 - loss: 0.2193 - val_accuracy: 0.9430 - val_loss: 0.1846\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9448 - loss: 0.1727\n",
            "Epoch 16: val_loss did not improve from 0.18461\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9448 - loss: 0.1727 - val_accuracy: 0.9305 - val_loss: 0.2241\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9372 - loss: 0.1935\n",
            "Epoch 17: val_loss did not improve from 0.18461\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9372 - loss: 0.1935 - val_accuracy: 0.9358 - val_loss: 0.2057\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9434 - loss: 0.1680\n",
            "Epoch 18: val_loss did not improve from 0.18461\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 239ms/step - accuracy: 0.9434 - loss: 0.1680 - val_accuracy: 0.9268 - val_loss: 0.2224\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9338 - loss: 0.1939\n",
            "Epoch 19: val_loss improved from 0.18461 to 0.16351, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m123s\u001b[0m 243ms/step - accuracy: 0.9338 - loss: 0.1939 - val_accuracy: 0.9513 - val_loss: 0.1635\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9464 - loss: 0.1630\n",
            "Epoch 20: val_loss did not improve from 0.16351\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 239ms/step - accuracy: 0.9464 - loss: 0.1630 - val_accuracy: 0.9373 - val_loss: 0.1947\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 186ms/step - accuracy: 0.9430 - loss: 0.1691\n",
            "Epoch 21: val_loss improved from 0.16351 to 0.16010, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 243ms/step - accuracy: 0.9430 - loss: 0.1691 - val_accuracy: 0.9460 - val_loss: 0.1601\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9521 - loss: 0.1471\n",
            "Epoch 22: val_loss improved from 0.16010 to 0.13383, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 244ms/step - accuracy: 0.9521 - loss: 0.1471 - val_accuracy: 0.9553 - val_loss: 0.1338\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9629 - loss: 0.1136\n",
            "Epoch 23: val_loss improved from 0.13383 to 0.09996, saving model to best_model2.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m124s\u001b[0m 245ms/step - accuracy: 0.9629 - loss: 0.1136 - val_accuracy: 0.9675 - val_loss: 0.1000\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9596 - loss: 0.1277\n",
            "Epoch 24: val_loss did not improve from 0.09996\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9595 - loss: 0.1278 - val_accuracy: 0.9330 - val_loss: 0.2164\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9421 - loss: 0.1851\n",
            "Epoch 25: val_loss did not improve from 0.09996\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9421 - loss: 0.1851 - val_accuracy: 0.9615 - val_loss: 0.1139\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9627 - loss: 0.1145\n",
            "Epoch 26: val_loss did not improve from 0.09996\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9627 - loss: 0.1146 - val_accuracy: 0.9582 - val_loss: 0.1319\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9588 - loss: 0.1253\n",
            "Epoch 27: val_loss did not improve from 0.09996\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m121s\u001b[0m 239ms/step - accuracy: 0.9588 - loss: 0.1254 - val_accuracy: 0.9555 - val_loss: 0.1234\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 187ms/step - accuracy: 0.9595 - loss: 0.1279\n",
            "Epoch 28: val_loss did not improve from 0.09996\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m122s\u001b[0m 240ms/step - accuracy: 0.9595 - loss: 0.1279 - val_accuracy: 0.9473 - val_loss: 0.1760\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 23.\n",
            "Training completed in 57.92 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CarNetV2\n",
        "val_loss, val_accuracy = CarNetV2.evaluate(val_dataset)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kAII04IOOzx7",
        "outputId": "b8bbaeb8-be43-49cd-c3f9-44fa6b33f1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 206ms/step - accuracy: 0.9672 - loss: 0.1022\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.11648868769407272\n",
            "Validation Accuracy: 0.9647499918937683\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetune the model with InceptionV3 weights with 3 layers in the fully-connected layers and Leaky ReLu as the activation function"
      ],
      "metadata": {
        "id": "LJatP0gBkFrQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Name\n",
        "name3 = \"CarNetV3\"\n",
        "\n",
        "# Pretrained Model\n",
        "base_model = InceptionV3(include_top=False, input_shape=(IMAGE_HEIGHT, IMAGE_WIDTH, NUM_CHANNELS), weights='imagenet')\n",
        "base_model.trainable = False # Freeze the Weights\n",
        "\n",
        "# Model\n",
        "CarNetV3 = Sequential([\n",
        "    base_model,\n",
        "    GlobalAvgPool2D(),\n",
        "    Dense(224, activation='leaky_relu'),\n",
        "    Dense(NUM_CLASSES, activation='softmax')\n",
        "], name=name3)\n",
        "\n",
        "CarNetV3.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, verbose=1, restore_best_weights=True),\n",
        "    ModelCheckpoint(filepath='best_model3.keras', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qg4g6NvVBUbP",
        "outputId": "54708fc4-6301-4852-93a4-f8a43d2d7437"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m87910968/87910968\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "EPOCHS = 100\n",
        "start_time = time.time()\n",
        "history = CarNetV3.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "execution_time = (time.time() - start_time) / 60.0\n",
        "print(f\"Training completed in {execution_time:.2f} minutes\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NHGY3_DKCivY",
        "outputId": "09a53adc-03d6-41b0-d90f-068fd4ffb051"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "    500/Unknown \u001b[1m49s\u001b[0m 65ms/step - accuracy: 0.0596 - loss: 4.6848"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_loss improved from inf to 3.36879, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 99ms/step - accuracy: 0.0597 - loss: 4.6838 - val_accuracy: 0.2020 - val_loss: 3.3688\n",
            "Epoch 2/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.2283 - loss: 3.1954\n",
            "Epoch 2: val_loss improved from 3.36879 to 2.64928, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 90ms/step - accuracy: 0.2283 - loss: 3.1953 - val_accuracy: 0.3392 - val_loss: 2.6493\n",
            "Epoch 3/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.3486 - loss: 2.5855\n",
            "Epoch 3: val_loss improved from 2.64928 to 2.15760, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.3486 - loss: 2.5855 - val_accuracy: 0.4442 - val_loss: 2.1576\n",
            "Epoch 4/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.4480 - loss: 2.1485\n",
            "Epoch 4: val_loss improved from 2.15760 to 1.83141, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 90ms/step - accuracy: 0.4480 - loss: 2.1485 - val_accuracy: 0.5293 - val_loss: 1.8314\n",
            "Epoch 5/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5285 - loss: 1.7775\n",
            "Epoch 5: val_loss improved from 1.83141 to 1.51898, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.5285 - loss: 1.7777 - val_accuracy: 0.6068 - val_loss: 1.5190\n",
            "Epoch 6/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.5951 - loss: 1.5151\n",
            "Epoch 6: val_loss improved from 1.51898 to 1.39971, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.5951 - loss: 1.5153 - val_accuracy: 0.6177 - val_loss: 1.3997\n",
            "Epoch 7/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6434 - loss: 1.3103\n",
            "Epoch 7: val_loss improved from 1.39971 to 1.10736, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.6434 - loss: 1.3104 - val_accuracy: 0.6957 - val_loss: 1.1074\n",
            "Epoch 8/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6971 - loss: 1.1155\n",
            "Epoch 8: val_loss improved from 1.10736 to 0.98867, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 90ms/step - accuracy: 0.6970 - loss: 1.1156 - val_accuracy: 0.7258 - val_loss: 0.9887\n",
            "Epoch 9/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7352 - loss: 0.9447\n",
            "Epoch 9: val_loss improved from 0.98867 to 0.88028, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.7351 - loss: 0.9449 - val_accuracy: 0.7530 - val_loss: 0.8803\n",
            "Epoch 10/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7705 - loss: 0.8032\n",
            "Epoch 10: val_loss improved from 0.88028 to 0.77901, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 90ms/step - accuracy: 0.7705 - loss: 0.8034 - val_accuracy: 0.7872 - val_loss: 0.7790\n",
            "Epoch 11/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8008 - loss: 0.6969\n",
            "Epoch 11: val_loss improved from 0.77901 to 0.67560, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 90ms/step - accuracy: 0.8008 - loss: 0.6970 - val_accuracy: 0.8080 - val_loss: 0.6756\n",
            "Epoch 12/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8282 - loss: 0.5917\n",
            "Epoch 12: val_loss improved from 0.67560 to 0.58436, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.8282 - loss: 0.5918 - val_accuracy: 0.8325 - val_loss: 0.5844\n",
            "Epoch 13/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8543 - loss: 0.5102\n",
            "Epoch 13: val_loss improved from 0.58436 to 0.46369, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.8542 - loss: 0.5103 - val_accuracy: 0.8735 - val_loss: 0.4637\n",
            "Epoch 14/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8818 - loss: 0.4166\n",
            "Epoch 14: val_loss did not improve from 0.46369\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.8817 - loss: 0.4168 - val_accuracy: 0.8503 - val_loss: 0.5075\n",
            "Epoch 15/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8841 - loss: 0.3984\n",
            "Epoch 15: val_loss improved from 0.46369 to 0.39960, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.8841 - loss: 0.3985 - val_accuracy: 0.8848 - val_loss: 0.3996\n",
            "Epoch 16/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9114 - loss: 0.3161\n",
            "Epoch 16: val_loss improved from 0.39960 to 0.34946, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 89ms/step - accuracy: 0.9114 - loss: 0.3162 - val_accuracy: 0.9028 - val_loss: 0.3495\n",
            "Epoch 17/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9127 - loss: 0.2990\n",
            "Epoch 17: val_loss improved from 0.34946 to 0.29833, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.9127 - loss: 0.2991 - val_accuracy: 0.9087 - val_loss: 0.2983\n",
            "Epoch 18/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9267 - loss: 0.2638\n",
            "Epoch 18: val_loss did not improve from 0.29833\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.9267 - loss: 0.2639 - val_accuracy: 0.8905 - val_loss: 0.3490\n",
            "Epoch 19/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9096 - loss: 0.2942\n",
            "Epoch 19: val_loss improved from 0.29833 to 0.26520, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.9096 - loss: 0.2942 - val_accuracy: 0.9222 - val_loss: 0.2652\n",
            "Epoch 20/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9356 - loss: 0.2168\n",
            "Epoch 20: val_loss did not improve from 0.26520\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9356 - loss: 0.2169 - val_accuracy: 0.9107 - val_loss: 0.2921\n",
            "Epoch 21/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9288 - loss: 0.2382\n",
            "Epoch 21: val_loss improved from 0.26520 to 0.23459, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.9287 - loss: 0.2383 - val_accuracy: 0.9287 - val_loss: 0.2346\n",
            "Epoch 22/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9395 - loss: 0.1939\n",
            "Epoch 22: val_loss did not improve from 0.23459\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9395 - loss: 0.1939 - val_accuracy: 0.9230 - val_loss: 0.2532\n",
            "Epoch 23/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9443 - loss: 0.1760\n",
            "Epoch 23: val_loss improved from 0.23459 to 0.20176, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.9443 - loss: 0.1760 - val_accuracy: 0.9402 - val_loss: 0.2018\n",
            "Epoch 24/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9471 - loss: 0.1759\n",
            "Epoch 24: val_loss did not improve from 0.20176\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9470 - loss: 0.1760 - val_accuracy: 0.8957 - val_loss: 0.3248\n",
            "Epoch 25/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9195 - loss: 0.2439\n",
            "Epoch 25: val_loss improved from 0.20176 to 0.16466, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 87ms/step - accuracy: 0.9195 - loss: 0.2439 - val_accuracy: 0.9465 - val_loss: 0.1647\n",
            "Epoch 26/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9490 - loss: 0.1610\n",
            "Epoch 26: val_loss did not improve from 0.16466\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9489 - loss: 0.1610 - val_accuracy: 0.9330 - val_loss: 0.1999\n",
            "Epoch 27/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9508 - loss: 0.1648\n",
            "Epoch 27: val_loss did not improve from 0.16466\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9508 - loss: 0.1648 - val_accuracy: 0.9383 - val_loss: 0.1992\n",
            "Epoch 28/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9467 - loss: 0.1701\n",
            "Epoch 28: val_loss improved from 0.16466 to 0.12615, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 88ms/step - accuracy: 0.9467 - loss: 0.1701 - val_accuracy: 0.9590 - val_loss: 0.1261\n",
            "Epoch 29/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9425 - loss: 0.1785\n",
            "Epoch 29: val_loss did not improve from 0.12615\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9425 - loss: 0.1786 - val_accuracy: 0.9103 - val_loss: 0.2842\n",
            "Epoch 30/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9477 - loss: 0.1729\n",
            "Epoch 30: val_loss did not improve from 0.12615\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9477 - loss: 0.1729 - val_accuracy: 0.9542 - val_loss: 0.1568\n",
            "Epoch 31/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9693 - loss: 0.0995\n",
            "Epoch 31: val_loss did not improve from 0.12615\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 85ms/step - accuracy: 0.9693 - loss: 0.0996 - val_accuracy: 0.9308 - val_loss: 0.2266\n",
            "Epoch 32/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9444 - loss: 0.1818\n",
            "Epoch 32: val_loss did not improve from 0.12615\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 85ms/step - accuracy: 0.9444 - loss: 0.1818 - val_accuracy: 0.9075 - val_loss: 0.2809\n",
            "Epoch 33/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9477 - loss: 0.1637\n",
            "Epoch 33: val_loss improved from 0.12615 to 0.10857, saving model to best_model3.keras\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 88ms/step - accuracy: 0.9477 - loss: 0.1637 - val_accuracy: 0.9643 - val_loss: 0.1086\n",
            "Epoch 34/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9590 - loss: 0.1239\n",
            "Epoch 34: val_loss did not improve from 0.10857\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - accuracy: 0.9590 - loss: 0.1240 - val_accuracy: 0.9430 - val_loss: 0.1727\n",
            "Epoch 35/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9569 - loss: 0.1265\n",
            "Epoch 35: val_loss did not improve from 0.10857\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 86ms/step - accuracy: 0.9569 - loss: 0.1266 - val_accuracy: 0.9490 - val_loss: 0.1523\n",
            "Epoch 36/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9534 - loss: 0.1418\n",
            "Epoch 36: val_loss did not improve from 0.10857\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 86ms/step - accuracy: 0.9534 - loss: 0.1419 - val_accuracy: 0.9477 - val_loss: 0.1750\n",
            "Epoch 37/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9585 - loss: 0.1289\n",
            "Epoch 37: val_loss did not improve from 0.10857\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 85ms/step - accuracy: 0.9585 - loss: 0.1290 - val_accuracy: 0.9482 - val_loss: 0.1520\n",
            "Epoch 38/100\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9575 - loss: 0.1263\n",
            "Epoch 38: val_loss did not improve from 0.10857\n",
            "\u001b[1m500/500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 85ms/step - accuracy: 0.9575 - loss: 0.1264 - val_accuracy: 0.9220 - val_loss: 0.2422\n",
            "Epoch 38: early stopping\n",
            "Restoring model weights from the end of the best epoch: 33.\n",
            "Training completed in 29.14 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate CarNetV3\n",
        "val_loss, val_accuracy = CarNetV3.evaluate(val_dataset)\n",
        "print(f\"Validation Loss: {val_loss}\")\n",
        "print(f\"Validation Accuracy: {val_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hN_wYiw0PImj",
        "outputId": "0be56928-412d-4708-9f9f-e9513178fe13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 64ms/step - accuracy: 0.9607 - loss: 0.1217\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/lib/python3.10/contextlib.py:153: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
            "  self.gen.throw(typ, value, traceback)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss: 0.1162281259894371\n",
            "Validation Accuracy: 0.9627500176429749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We decided to move on with CarNetV3 which gives a high validation accuracy and shortest training time."
      ],
      "metadata": {
        "id": "TlpQjRGVkMMy"
      }
    }
  ]
}